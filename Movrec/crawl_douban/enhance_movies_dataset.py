#!/usr/bin/env python3
"""
å¢å¼º movies.csv æ•°æ®é›† - æ·»åŠ çŸ­è¯„æ•°æ®
"""

import pandas as pd
import requests
import time
import random
from bs4 import BeautifulSoup
import os

def parse_movie_reviews(movie_id: str, sess: requests.Session, max_reviews=20) -> list:
    """çˆ¬å–çŸ­è¯„çš„å‡½æ•°"""
    reviews_list = []
    
    try:
        print(f"    æ­£åœ¨çˆ¬å–çŸ­è¯„...", end="")
        
        for page in range(2):  # çˆ¬å–å‰2é¡µ
            if len(reviews_list) >= max_reviews:
                break
                
            review_url = f"https://movie.douban.com/subject/{movie_id}/comments"
            params = {'start': page * 20, 'limit': 20, 'status': 'P', 'sort': 'new_score'}
            
            try:
                response = sess.get(review_url, params=params, timeout=15)
                soup = BeautifulSoup(response.text, 'html.parser')
                comment_items = soup.find_all('div', class_='comment-item')
                
                for item in comment_items:
                    if len(reviews_list) >= max_reviews:
                        break
                    comment = item.find('span', class_='short')
                    if comment:
                        review_text = comment.get_text().strip()
                        if len(review_text) > 5:
                            reviews_list.append(review_text)
                
                time.sleep(random.uniform(1, 2))
                
            except Exception as e:
                print(f"ç¬¬{page+1}é¡µå¤±è´¥: {e}", end=" ")
                continue
                
        print(f"è·å¾— {len(reviews_list)} æ¡çŸ­è¯„")
                
    except Exception as e:
        print(f"çˆ¬å–å¤±è´¥: {e}")
    
    return reviews_list

def enhance_movies_csv():
    """å¢å¼º movies.csv æ•°æ®é›†"""
    print("=== å¼€å§‹å¢å¼º movies.csv æ•°æ®é›† ===")
    
    # æŸ¥æ‰¾æ•°æ®é›†æ–‡ä»¶
    input_file = "../movies.csv"
    
    if not os.path.exists(input_file):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {input_file}")
        print("æ­£åœ¨æœç´¢æ–‡ä»¶...")
        # åœ¨é¡¹ç›®æ ¹ç›®å½•æœç´¢
        for root, dirs, files in os.walk("../.."):
            if "movies.csv" in files:
                input_file = os.path.join(root, "movies.csv")
                break
    
    if not os.path.exists(input_file):
        print("âŒ æ²¡æœ‰æ‰¾åˆ° movies.csv æ–‡ä»¶")
        return
    
    print(f"æ‰¾åˆ°æ•°æ®é›†: {input_file}")
    
    # è¯»å–æ•°æ®
    try:
        df = pd.read_csv(input_file, encoding='utf-8')
    except:
        try:
            df = pd.read_csv(input_file, encoding='gbk')
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return
    
    print(f"æ•°æ®é›†ä¿¡æ¯:")
    print(f"  - æ€»ç”µå½±æ•°: {len(df)}")
    print(f"  - åˆ—å: {list(df.columns)}")
    print(f"  - å‰3éƒ¨ç”µå½±:")
    for i in range(min(3, len(df))):
        movie_name = df.iloc[i].get('NAME', 'æœªçŸ¥')
        print(f"    {i+1}. {movie_name}")
    
    # åˆ›å»ºå¢å¼ºç‰ˆæ•°æ®é›†
    output_file = "movies_with_reviews.csv"
    
    # æ·»åŠ çŸ­è¯„åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if 'reviews' not in df.columns:
        df['reviews'] = ''
    if 'reviews_count' not in df.columns:
        df['reviews_count'] = 0
    
    # è®¾ç½®ä¼šè¯
    sess = requests.Session()
    sess.headers.update({
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Referer": "https://movie.douban.com/",
    })
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç”µå½±IDåˆ—
    has_movie_id = any(col in df.columns for col in ['MOVIE_ID', 'movie_id', 'douban_id', 'subject_id'])
    
    if not has_movie_id:
        print("\nâš ï¸  æ•°æ®é›†æ²¡æœ‰ç”µå½±IDåˆ—ï¼Œéœ€è¦å…ˆè·å–è±†ç“£ID")
        print("ç”±äºæ—¶é—´å…³ç³»ï¼Œæˆ‘ä»¬å…ˆæµ‹è¯•å·²çŸ¥çš„ç”µå½±ID")
        # ä½¿ç”¨å·²çŸ¥çš„ç”µå½±IDæµ‹è¯•å‰3éƒ¨
        test_ids = ["1291546", "1300267", "1291578"]  # éœ¸ç‹åˆ«å§¬, ä¹±ä¸–ä½³äºº, ç‹¬ç«‹æ—¶ä»£
    else:
        # è·å–IDåˆ—å
        id_col = [col for col in ['MOVIE_ID', 'movie_id', 'douban_id', 'subject_id'] if col in df.columns][0]
        test_ids = df[id_col].head(3).tolist()
    
    print(f"\nå¼€å§‹å¢å¼ºå‰ 3 éƒ¨ç”µå½±çš„æ•°æ®...")
    
    enhanced_count = 0
    for i in range(min(3, len(df))):
        movie_name = df.iloc[i].get('NAME', f'ç”µå½±{i+1}')
        
        # å¦‚æœå·²ç»æœ‰çŸ­è¯„æ•°æ®ï¼Œè·³è¿‡
        if pd.notna(df.iloc[i].get('reviews')) and df.iloc[i].get('reviews_count', 0) > 0:
            print(f"{i+1}. {movie_name} - å·²æœ‰çŸ­è¯„æ•°æ®ï¼Œè·³è¿‡")
            continue
        
        if i < len(test_ids) and test_ids[i]:
            movie_id = str(test_ids[i])
            print(f"{i+1}. {movie_name} (ID: {movie_id})")
            
            try:
                reviews = parse_movie_reviews(movie_id, sess, max_reviews=15)
                df.at[i, 'reviews'] = " | ".join(reviews)
                df.at[i, 'reviews_count'] = len(reviews)
                enhanced_count += 1
                
            except Exception as e:
                print(f"  âŒ å¤±è´¥: {e}")
        else:
            print(f"{i+1}. {movie_name} - æ²¡æœ‰å¯ç”¨çš„ç”µå½±IDï¼Œè·³è¿‡")
        
        # å»¶æ—¶é¿å…è¢«å°
        if i < 2:  # å‰2éƒ¨ä¹‹åå»¶æ—¶
            wait_time = random.uniform(3, 5)
            print(f"    ç­‰å¾… {wait_time:.1f} ç§’...")
            time.sleep(wait_time)
    
    #ä¿å­˜ç»“æœ
    df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\nğŸ‰ å¢å¼ºå®Œæˆï¼")
    print(f"âœ… æˆåŠŸå¢å¼º {enhanced_count} éƒ¨ç”µå½±çš„æ•°æ®")
    print(f"ğŸ“ å¢å¼ºç‰ˆæ•°æ®é›†: {output_file}")
    print(f"ğŸ“Š æ€»ç”µå½±æ•°: {len(df)}")
    
    # æ˜¾ç¤ºå¢å¼ºç»“æœæ‘˜è¦
    print(f"\nå¢å¼ºç»“æœæ‘˜è¦:")
    enhanced_movies = df[df['reviews_count'] > 0].head(5)
    for _, row in enhanced_movies.iterrows():
        print(f"  - {row['NAME']}: {row['reviews_count']} æ¡çŸ­è¯„")

if __name__ == "__main__":
    enhance_movies_csv()
