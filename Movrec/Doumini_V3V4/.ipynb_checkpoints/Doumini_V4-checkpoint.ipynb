{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e90681ce-274f-45ea-b363-2cc59f966c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "movies=pd.read_csv('movies.csv')\n",
    "movies_db=pd.read_csv('movies_db.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7d32fe-8598-4d77-a276-0c161b824e04",
   "metadata": {},
   "source": [
    "### 1.æ•°æ®æ¸…æ´—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9e8a82f-7927-4898-bada-648184ed3d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1172 entries, 0 to 1171\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   subject_id  1172 non-null   object\n",
      " 1   title       1172 non-null   object\n",
      " 2   year        1172 non-null   object\n",
      " 3   rating      1168 non-null   object\n",
      " 4   directors   1169 non-null   object\n",
      " 5   INFO        1172 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 55.1+ KB\n"
     ]
    }
   ],
   "source": [
    "movies_db=movies_db.drop(\n",
    "    columns=['durations','votes']\n",
    ")\n",
    "movies_db['INFO'] = (\n",
    "    movies_db['genres'].fillna('').astype(str) + ' ' +\n",
    "    movies_db['countries'].fillna('').astype(str) + ' ' +\n",
    "    movies_db['reviews'].fillna('').astype(str)\n",
    ")\n",
    "\n",
    "movies_db = movies_db.drop(columns=['genres', 'countries', 'reviews'])\n",
    "movies_db.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e5479d-a17e-4ca0-8922-d2a80c3439ba",
   "metadata": {},
   "source": [
    "åˆ é™¤æ— ç”¨åˆ—å¹¶åªä¿ç•™è¯„åˆ†å¤§äº6.5çš„ç”µå½±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5e5bc38-02d2-4c94-a462-55a568c45ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.drop(\n",
    "    columns=['COVER','IMDB_ID','MINS','OFFICIAL_SITE','RELEASE_DATE','SLUG','ACTOR_IDS','DIRECTOR_IDS','LANGUAGES','GENRES','ALIAS','ACTORS']\n",
    ")\n",
    "movies = movies[movies['DOUBAN_SCORE'] >= 6.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12251fd-378e-479a-9c3c-357c235ec45b",
   "metadata": {},
   "source": [
    "ç­›é€‰è¯„åˆ†äººæ•°å¤§äº5000çš„ç”µå½±å¹¶é™åºæ’åˆ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "100e8223-7846-4eec-930a-e8434df5b53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new = movies[(movies['DOUBAN_VOTES'] >= 3000)].sort_values(by=['DOUBAN_SCORE','DOUBAN_VOTES'], ascending=[False,False])[['DIRECTORS','MOVIE_ID','NAME','DOUBAN_SCORE','STORYLINE','TAGS','REGIONS','YEAR']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f280483-5565-4977-836b-4cd4dce27a0a",
   "metadata": {},
   "source": [
    "### 2.ä½™å¼¦ç›¸ä¼¼åº¦æ¨¡å‹æ„å»º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eedd4aa0-ef2f-41a2-ba96-c0c59125c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new['INFO'] = (\n",
    "    movies['STORYLINE'].fillna('').astype(str) + \" \" +\n",
    "    movies['TAGS'].fillna('').astype(str) + \" \" +\n",
    "    movies['REGIONS'].fillna('').astype(str)\n",
    "#    + \" \" +\n",
    "#    movies['DIRECTORS'].fillna('').astype(str) + \" \" +\n",
    "#    movies['ACTORS'].fillna('').astype(str) + \" \" +\n",
    "#    movies['YEAR'].fillna('').astype(str)\n",
    ")\n",
    "movies_new = movies_new.drop(columns=['STORYLINE', 'TAGS', 'REGIONS'\n",
    "                                      #, 'DIRECTORS', 'ACTORS', 'YEAR'\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fe8b7f6-9dc8-4105-b2ff-d58e59db50e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5058 entries, 0 to 5057\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   DIRECTORS     4913 non-null   object\n",
      " 1   MOVIE_ID      5058 non-null   object\n",
      " 2   NAME          5058 non-null   object\n",
      " 3   DOUBAN_SCORE  5054 non-null   object\n",
      " 4   YEAR          5058 non-null   object\n",
      " 5   INFO          5058 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 237.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "movies_db_renamed = movies_db.rename(columns={\n",
    "    'subject_id': 'MOVIE_ID',\n",
    "    'title': 'NAME',\n",
    "    'year': 'YEAR',\n",
    "    'rating': 'DOUBAN_SCORE',\n",
    "    'directors': 'DIRECTORS'\n",
    "})\n",
    "\n",
    "movies_db_renamed = movies_db_renamed[['DIRECTORS', 'MOVIE_ID', 'NAME', 'DOUBAN_SCORE', 'YEAR', 'INFO']]\n",
    "\n",
    "movies_new = pd.concat([movies_new, movies_db_renamed], ignore_index=True)\n",
    "movies_new['NAME'] = movies_new['NAME'].apply(lambda x: ''.join(re.findall(r'[\\u4e00-\\u9fff]+', str(x))))\n",
    "\n",
    "print(movies_new.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea069d99-9363-4741-8bd3-32b733adab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#æ·»åŠ ä¸­æ–‡åˆ†è¯åº“\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "308629b3-bc33-486b-bb5a-64e9dff3ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸­æ–‡åˆ†è¯å™¨\n",
    "def chinese_tokenizer(text):\n",
    "    return jieba.lcut(str(text))\n",
    "stopwords = [\n",
    "    \"çš„\", \"äº†\", \"åœ¨\", \"æ˜¯\", \"æˆ‘\", \"æœ‰\", \"å’Œ\", \"å°±\", \"ä¸\", \"äºº\", \n",
    "    \"éƒ½\", \"ä¸€\", \"ä¸€ä¸ª\", \"ä¸Š\", \"ä¹Ÿ\", \"å¾ˆ\", \"åˆ°\", \"è¯´\", \"è¦\", \"å»\",\n",
    "    \"ä½ \", \"ä¼š\", \"ç€\", \"æ²¡æœ‰\", \"çœ‹\", \"å¥½\", \"è‡ªå·±\", \"è¿™\", \"é‚£\", \n",
    "    \"ä¸º\", \"ä¹‹\", \"å¯¹\", \"ä¸\", \"è€Œ\", \"å¹¶\", \"ç­‰\", \"è¢«\", \"åŠ\", \"æˆ–\",\n",
    "    \"ä½†\", \"æ‰€ä»¥\", \"å¦‚æœ\", \"å› ä¸º\", \"ç„¶å\", \"è€Œä¸”\", \"é‚£ä¹ˆ\", \"ä»–ä»¬\", \n",
    "    \"æˆ‘ä»¬\", \"ä½ ä»¬\", \"å®ƒä»¬\", \"ä»€ä¹ˆ\", \"å“ªä¸ª\", \"å“ªäº›\", \"å“ªé‡Œ\", \"æ—¶å€™\",\n",
    "    \"ä»–\", \"å¥¹\", \"å®ƒ\", \"å’±ä»¬\", \"å¤§å®¶\", \"è°\", \"æ€æ ·\", \"æ€ä¹ˆ\", \"å¤šå°‘\", \"ä¸ºä»€ä¹ˆ\",\n",
    "    \"è¿™é‡Œ\", \"é‚£é‡Œ\", \"è¿™æ ·\", \"é‚£æ ·\", \"è¿™ä¸ª\", \"é‚£ä¸ª\", \"è¿™äº›\", \"é‚£äº›\",\n",
    "    \"åœ°\", \"å¾—\", \"æ‰€\", \"è¿‡\", \"å—\", \"å‘¢\", \"å§\", \"å•Š\", \"å‘€\", \"å˜›\", \"å“‡\", \"å•¦\",\n",
    "    \"ä»\", \"è‡ª\", \"ä»¥\", \"å‘\", \"å…³äº\", \"å¯¹äº\", \"æ ¹æ®\", \"æŒ‰ç…§\", \"é€šè¿‡\", \"ç”±äº\",\n",
    "    \"å¹¶ä¸”\", \"æˆ–è€…\", \"è™½ç„¶\", \"å³ä½¿\", \"å°½ç®¡\", \"ä¸ç®¡\", \"åªè¦\", \"åªæœ‰\", \"é™¤é\",\n",
    "    \"æœ€\", \"å¤ª\", \"æ›´\", \"éå¸¸\", \"ååˆ†\", \"ç‰¹åˆ«\", \"æå…¶\", \"æ¯”è¾ƒ\", \"ç¨å¾®\", \"æœ‰ç‚¹\",\n",
    "    \"åˆš\", \"æ‰\", \"æ­£åœ¨\", \"å·²ç»\", \"æ›¾ç»\", \"é©¬ä¸Š\", \"ç«‹åˆ»\", \"æ°¸è¿œ\", \"ä¸€ç›´\", \"æ€»æ˜¯\",\n",
    "    \"å¸¸å¸¸\", \"ç»å¸¸\", \"å¾€å¾€\", \"ä¸æ–­\", \"å¶å°”\", \"åˆ\", \"å†\", \"è¿˜\", \"ä»…\", \"å…‰\",\n",
    "    \"èƒ½\", \"èƒ½å¤Ÿ\", \"å¯ä»¥\", \"å¯èƒ½\", \"åº”è¯¥\", \"åº”å½“\", \"æƒ³\", \"æ„¿æ„\", \"è‚¯\", \"æ•¢\",\n",
    "    \"æ¥\", \"å»\", \"è¿›\", \"å‡º\", \"å›\", \"èµ·\", \"å¼€\",\n",
    "    \"äº›\", \"ä¸€äº›\", \"æ‰€æœ‰\", \"æ¯ä¸ª\", \"æŸä¸ª\", \"å„ç§\", \"å¤šä¸ª\", \"å‡ ä¸ª\", \"ç¬¬ä¸€\", \"ç¬¬äºŒ\",\n",
    "    \"å°±æ˜¯\", \"åªæ˜¯\", \"å¯æ˜¯\", \"çœŸæ˜¯\", \"ä¹Ÿæ˜¯\", \"ä¸æ˜¯\", \"ä¹Ÿæ˜¯\", \"å°±æ˜¯\", \"æ­£æ˜¯\",\n",
    "    \"ä¸€æ ·\", \"ä¸€èˆ¬\", \"ä¸€ç‚¹\", \"ä¸€èµ·\", \"ä¸€ç›´\", \"ä¸€ä¸‹\", \"ä¸€äº›\", \"ä¸€ç§\", \"ä¸€æ¬¡\"\n",
    "]\n",
    "cv = CountVectorizer(\n",
    "    max_features=10000,\n",
    "    tokenizer=chinese_tokenizer,\n",
    "    stop_words=stopwords,   # ä¸­æ–‡åœç”¨è¯è¡¨ï¼ˆå¦‚æœæœ‰å°±ä¼  listï¼‰\n",
    "    token_pattern=None      # å¿…é¡»è®¾ Noneï¼Œå¦åˆ™ tokenizer ä¼šè¢«è¦†ç›–\n",
    ")\n",
    "\n",
    "vector = cv.fit_transform(movies_new['INFO'].astype(str)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57a6fe53-971b-4ded-b2ce-f0b2663f3b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 131ms/step - loss: 0.0495 - val_loss: 0.0873\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - loss: 0.0199 - val_loss: 0.0628\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - loss: 0.0150 - val_loss: 0.0458\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - loss: 0.0131 - val_loss: 0.0396\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - loss: 0.0123 - val_loss: 0.0378\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - loss: 0.0119 - val_loss: 0.0351\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - loss: 0.0115 - val_loss: 0.0340\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - loss: 0.0109 - val_loss: 0.0333\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - loss: 0.0107 - val_loss: 0.0314\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - loss: 0.0105 - val_loss: 0.0311\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - loss: 0.0102 - val_loss: 0.0304\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - loss: 0.0101 - val_loss: 0.0297\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - loss: 0.0099 - val_loss: 0.0292\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - loss: 0.0098 - val_loss: 0.0283\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - loss: 0.0097 - val_loss: 0.0287\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - loss: 0.0096 - val_loss: 0.0280\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - loss: 0.0094 - val_loss: 0.0275\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - loss: 0.0094 - val_loss: 0.0271\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - loss: 0.0093 - val_loss: 0.0271\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - loss: 0.0092 - val_loss: 0.0267\n"
     ]
    }
   ],
   "source": [
    "# ========= å»å™ªå˜åˆ†è‡ªç¼–ç å™¨ï¼ˆDVAEï¼‰â€” ç¨³å®šç‰ˆï¼ˆè‡ªå®šä¹‰LayeråŠ KLï¼‰ =========\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "inp_dim    = vector.shape[1]\n",
    "code_dim   = 64            # å¯æ”¹ 64/128\n",
    "epochs     = 20\n",
    "batch_size = 256\n",
    "beta_kl    = 1.0          # Î²-VAE ç³»æ•°\n",
    "\n",
    "# ç¡®ä¿ dtype ç¨³å®š\n",
    "vector = vector.astype(\"float32\", copy=False)\n",
    "\n",
    "# --- ç¼–ç å™¨ï¼šè¾“å…¥ç«¯å»å™ª ---\n",
    "inputs = keras.Input(shape=(inp_dim,), name=\"bow_counts\")\n",
    "x = keras.layers.GaussianNoise(0.15)(inputs)          # å»å™ªï¼›ä¹Ÿå¯æ¢ Dropout(0.3)\n",
    "x = keras.layers.Dense(1000, activation=\"selu\")(x)\n",
    "x = keras.layers.Dense(256,  activation=\"selu\")(x)\n",
    "z_mean   = keras.layers.Dense(code_dim, name=\"z_mean\")(x)\n",
    "z_logvar = keras.layers.Dense(code_dim, name=\"z_logvar\")(x)\n",
    "\n",
    "def reparameterize(args):\n",
    "    mu, logvar = args\n",
    "    eps = tf.random.normal(shape=tf.shape(mu))\n",
    "    return mu + tf.exp(0.5 * logvar) * eps\n",
    "\n",
    "z = keras.layers.Lambda(reparameterize, name=\"z\")([z_mean, z_logvar])\n",
    "\n",
    "# æ‰“åŒ…ä¸€ä¸ª encoderï¼ˆåŒ…å«ä¸‰ä¸ªè¾“å‡ºï¼šmean, logvar, zï¼‰\n",
    "encoder = keras.Model(inputs, [z_mean, z_logvar, z], name=\"dvae_encoder\")\n",
    "\n",
    "# --- è§£ç å™¨ï¼šçº¿æ€§è¾“å‡ºï¼Œç”¨ MSE é‡æ„è®¡æ•° ---\n",
    "latent_inputs = keras.Input(shape=(code_dim,), name=\"z_in\")\n",
    "d = keras.layers.Dense(256,  activation=\"selu\")(latent_inputs)\n",
    "d = keras.layers.Dense(1000, activation=\"selu\")(d)\n",
    "recons = keras.layers.Dense(inp_dim, activation=None, name=\"recon\")(d)\n",
    "decoder = keras.Model(latent_inputs, recons, name=\"dvae_decoder\")\n",
    "\n",
    "# --- è‡ªå®šä¹‰ KL å±‚ï¼šæŠŠ KL æ­£åˆ™é€šè¿‡ layer.add_loss() æ³¨å…¥ ---\n",
    "class KLDivergenceLayer(keras.layers.Layer):\n",
    "    def __init__(self, beta=1.0, scale=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.beta = beta\n",
    "        self.scale = scale  # ç”¨äºä¸ MSE æ ‡åº¦å¯¹é½\n",
    "\n",
    "    def call(self, inputs):\n",
    "        mu, logvar = inputs\n",
    "        # KL = -0.5 * sum(1 + logvar - exp(logvar) - mu^2)\n",
    "        kl_per_sample = -0.5 * tf.reduce_sum(\n",
    "            1.0 + logvar - tf.exp(logvar) - tf.square(mu), axis=1\n",
    "        )\n",
    "        kl = tf.reduce_mean(kl_per_sample) / float(self.scale)\n",
    "        self.add_loss(self.beta * kl)\n",
    "        # è¿”å›ä¸ªâ€œå ä½è¾“å‡ºâ€ï¼Œä¸å‚ä¸åç»­è®¡ç®—\n",
    "        return tf.zeros_like(mu[:, :1])\n",
    "\n",
    "# --- ç»„è£… DVAEï¼šé‡æ„ + KLå±‚ï¼ˆåªä¸ºåŠ lossï¼Œä¸æ”¹è®¡ç®—å›¾ï¼‰---\n",
    "z_mean_out, z_logvar_out, z_out = encoder(inputs)\n",
    "_ = KLDivergenceLayer(beta=beta_kl, scale=inp_dim, name=\"kl_reg\")([z_mean_out, z_logvar_out])\n",
    "recons_out = decoder(z_out)\n",
    "\n",
    "vae = keras.Model(inputs, recons_out, name=\"dvae\")\n",
    "\n",
    "# --- è®­ç»ƒï¼šé‡æ„ç”¨ MSEï¼›KL å·²ç”± KL å±‚æ³¨å…¥ ---\n",
    "vae.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mse\")\n",
    "vae.fit(vector, vector, epochs=epochs, batch_size=batch_size, validation_split=0.1, verbose=1)\n",
    "\n",
    "# --- ç”¨ z_mean ä½œä¸ºç”µå½±å‘é‡ï¼ˆæ›´ç¨³ã€æ›´å¯æ’å€¼ï¼‰---\n",
    "z_mean_val = encoder.predict(vector, verbose=0)[0]   # å½¢çŠ¶: [N, code_dim]\n",
    "feature = z_mean_val\n",
    "\n",
    "# ========= DVAE ç»“æŸ =========\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d96bd8f-46b9-4c89-8143-6cd5ac72dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52e7374e-5af3-4825-8f95-e94e501adba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def recommand(movie_name, topk=5):\n",
    "    label_idx = movies_new.index[movies_new['NAME'] == movie_name]\n",
    "    if len(label_idx) == 0:\n",
    "        print(\"æœªæ‰¾åˆ°è¯¥å½±ç‰‡\")\n",
    "        return\n",
    "    pos = movies_new.index.get_loc(label_idx[0])\n",
    "\n",
    "    sims = similarity[pos]\n",
    "    cand = np.argsort(-sims)\n",
    "    cand = cand[cand != pos][:topk]\n",
    "\n",
    "    recs = []\n",
    "    for j in cand:\n",
    "        recs.append({\n",
    "            \"ç”µå½±å\": movies_new.iloc[j]['NAME'],\n",
    "            \"è±†ç“£è¯„åˆ†\": movies_new.iloc[j]['DOUBAN_SCORE'],\n",
    "        })\n",
    "    df = pd.DataFrame(recs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d1a0c22-b1c2-4f17-b6ab-8d8ee94ed40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ç”µå½±å</th>\n",
       "      <th>è±†ç“£è¯„åˆ†</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ç”˜æ³‰ç›ä¾¬</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>è´¨æ•°çš„å­¤ç‹¬</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ç½—å°”å¨œçš„æ²‰é»˜</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>å¥³æ€§ç˜¾è€…ç¬¬ä¸€éƒ¨</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>é˜¿é»›å°”çš„ç”Ÿæ´»</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ç”µå½±å  è±†ç“£è¯„åˆ†\n",
       "0     ç”˜æ³‰ç›ä¾¬   8.0\n",
       "1    è´¨æ•°çš„å­¤ç‹¬   7.0\n",
       "2   ç½—å°”å¨œçš„æ²‰é»˜   7.5\n",
       "3  å¥³æ€§ç˜¾è€…ç¬¬ä¸€éƒ¨   7.8\n",
       "4   é˜¿é»›å°”çš„ç”Ÿæ´»   8.4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommand(\"åˆæ³•å‰¯æœ¬\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02e2e2c4-aef7-46a4-aa2c-b63b74ef0de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, scrolledtext, messagebox\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # â† æ–°å¢\n",
    "\n",
    "class MovieCollectionRecommendationApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"ğŸ¬ ç”µå½±é›†åˆæ¨èç³»ç»Ÿ\")\n",
    "        self.root.geometry(\"900x700\")\n",
    "        \n",
    "        # ç»‘å®šå…¨å±€æ•°æ®ï¼ˆmovies_new / similarity / featureï¼‰\n",
    "        self.movies_df = globals().get('movies_new', None)\n",
    "        self.similarity = globals().get('similarity', None)\n",
    "        self.feature = globals().get('feature', None)  # å¦‚ DVAE çš„ z_mean\n",
    "        \n",
    "        # è‡ªåŠ¨å…œåº•ï¼šè‹¥æ²¡æœ‰ç›¸ä¼¼åº¦çŸ©é˜µï¼Œä½†æœ‰ä½ç»´è¡¨å¾ï¼Œåˆ™ç”¨ä½™å¼¦æ„å»ºä¸€æ¬¡\n",
    "        self.ensure_similarity_ready()\n",
    "\n",
    "        self.setup_ui()\n",
    "    \n",
    "    # ========== æ–°å¢ï¼šè‡ªåŠ¨å‡†å¤‡ç›¸ä¼¼åº¦ ==========\n",
    "    def ensure_similarity_ready(self):\n",
    "        if self.movies_df is None:\n",
    "            raise RuntimeError(\"é”™è¯¯ï¼šæœªæ‰¾åˆ°å…¨å±€å˜é‡ movies_newï¼ˆç”µå½±æ•°æ®è¡¨ï¼‰ã€‚\")\n",
    "        if self.similarity is None:\n",
    "            # ä¼˜å…ˆä½¿ç”¨ä½ç»´è¯­ä¹‰è¡¨å¾ï¼ˆAE/VAE/DVAEï¼‰\n",
    "            if self.feature is not None:\n",
    "                try:\n",
    "                    self.similarity = cosine_similarity(self.feature)\n",
    "                    globals()['similarity'] = self.similarity  # å†™å›å…¨å±€ï¼Œä¾¿äºå…¶å®ƒæ¨¡å—å¤ç”¨\n",
    "                    self.sim_source = \"ç”±ä½ç»´è¡¨å¾ï¼ˆfeatureï¼‰è‡ªåŠ¨è®¡ç®—\"\n",
    "                except Exception as e:\n",
    "                    raise RuntimeError(f\"æ ¹æ® feature è®¡ç®—ç›¸ä¼¼åº¦å¤±è´¥ï¼š{e}\")\n",
    "            else:\n",
    "                raise RuntimeError(\"é”™è¯¯ï¼šæœªæ‰¾åˆ°ç›¸ä¼¼åº¦çŸ©é˜µ similarityï¼Œä¸”æ²¡æœ‰ä½ç»´è¡¨å¾ featureã€‚è¯·å…ˆåœ¨ä¸Šæ¸¸æ„å»ºã€‚\")\n",
    "        else:\n",
    "            self.sim_source = \"ä½¿ç”¨ä¸Šæ¸¸æä¾›çš„ similarity çŸ©é˜µ\"\n",
    "\n",
    "    def setup_ui(self):\n",
    "        # æ ‡é¢˜\n",
    "        title_label = tk.Label(\n",
    "            self.root, \n",
    "            text=\"ğŸ¬ è±†MINIæ™ºèƒ½ç”µå½±é›†åˆæ¨èç³»ç»Ÿ\", \n",
    "            font=(\"Arial\", 16, \"bold\")\n",
    "        )\n",
    "        title_label.pack(pady=20)\n",
    "        \n",
    "        # è¾“å…¥åŒºåŸŸ\n",
    "        input_frame = tk.Frame(self.root)\n",
    "        input_frame.pack(pady=10, fill=tk.X, padx=20)\n",
    "        \n",
    "        # ç”µå½±é›†åˆè¾“å…¥\n",
    "        tk.Label(input_frame, text=\"è¾“å…¥ç”µå½±é›†åˆ:\", font=(\"Arial\", 12)).grid(row=0, column=0, sticky=\"w\", pady=5)\n",
    "        \n",
    "        input_help = tk.Label(input_frame, text=\"(å¤šä¸ªç”µå½±ç”¨é€—å·ã€åˆ†å·æˆ–æ¢è¡Œåˆ†éš”)\", font=(\"Arial\", 9), fg=\"gray\")\n",
    "        input_help.grid(row=0, column=1, sticky=\"w\", pady=5)\n",
    "        \n",
    "        self.movies_text = scrolledtext.ScrolledText(input_frame, height=4, width=60, font=(\"Arial\", 11))\n",
    "        self.movies_text.grid(row=1, column=0, columnspan=3, sticky=\"ew\", pady=5)\n",
    "        \n",
    "        # æ¨èè®¾ç½®åŒºåŸŸ\n",
    "        settings_frame = tk.Frame(self.root)\n",
    "        settings_frame.pack(pady=10, fill=tk.X, padx=20)\n",
    "        \n",
    "        tk.Label(settings_frame, text=\"æ¨èæ•°é‡:\", font=(\"Arial\", 12)).pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        self.topk_var = tk.StringVar(value=\"10\")\n",
    "        topk_spinbox = tk.Spinbox(\n",
    "            settings_frame, \n",
    "            from_=1, \n",
    "            to=50, \n",
    "            width=5, \n",
    "            textvariable=self.topk_var,\n",
    "            font=(\"Arial\", 12)\n",
    "        )\n",
    "        topk_spinbox.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        # æ¨èç­–ç•¥é€‰æ‹©\n",
    "        tk.Label(settings_frame, text=\"æ¨èç­–ç•¥:\", font=(\"Arial\", 12)).pack(side=tk.LEFT, padx=(20,5))\n",
    "        \n",
    "        self.strategy_var = tk.StringVar(value=\"average\")\n",
    "        strategy_combo = ttk.Combobox(\n",
    "            settings_frame,\n",
    "            textvariable=self.strategy_var,\n",
    "            values=[\"average\", \"maximum\", \"union\"],\n",
    "            state=\"readonly\",\n",
    "            width=10\n",
    "        )\n",
    "        strategy_combo.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        # ç­–ç•¥è¯´æ˜\n",
    "        strategy_help = tk.Label(settings_frame, text=\"(å¹³å‡ç›¸ä¼¼åº¦ | æœ€å¤§ç›¸ä¼¼åº¦ | å¹¶é›†ç›¸ä¼¼åº¦)\", font=(\"Arial\", 9), fg=\"gray\")\n",
    "        strategy_help.pack(side=tk.LEFT, padx=5)\n",
    "        \n",
    "        # æŒ‰é’®åŒºåŸŸ\n",
    "        button_frame = tk.Frame(self.root)\n",
    "        button_frame.pack(pady=10)\n",
    "        \n",
    "        recommend_btn = tk.Button(\n",
    "            button_frame,\n",
    "            text=\"å¼€å§‹æ¨è\",\n",
    "            command=self.recommend_movies,\n",
    "            font=(\"Arial\", 12, \"bold\"),\n",
    "            bg='#3498db',\n",
    "            fg='white',\n",
    "            padx=30,\n",
    "            pady=5\n",
    "        )\n",
    "        recommend_btn.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        clear_btn = tk.Button(\n",
    "            button_frame,\n",
    "            text=\"æ¸…ç©ºè¾“å…¥\",\n",
    "            command=self.clear_input,\n",
    "            font=(\"Arial\", 12),\n",
    "            bg='#95a5a6',\n",
    "            fg='white',\n",
    "            padx=20,\n",
    "            pady=5\n",
    "        )\n",
    "        clear_btn.pack(side=tk.LEFT, padx=10)\n",
    "        \n",
    "        # ç»“æœæ˜¾ç¤ºåŒºåŸŸ\n",
    "        result_frame = tk.Frame(self.root)\n",
    "        result_frame.pack(fill=tk.BOTH, expand=True, padx=20, pady=10)\n",
    "        \n",
    "        # åˆ›å»ºæ–‡æœ¬æ¡†ç”¨äºæ˜¾ç¤ºç»“æœ\n",
    "        self.result_text = scrolledtext.ScrolledText(\n",
    "            result_frame,\n",
    "            wrap=tk.WORD,\n",
    "            font=(\"Arial\", 11),\n",
    "            padx=10,\n",
    "            pady=10\n",
    "        )\n",
    "        self.result_text.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # çŠ¶æ€æ \n",
    "        self.status_var = tk.StringVar(value=f\"å°±ç»ª - {self.sim_source}\")\n",
    "        status_bar = tk.Label(\n",
    "            self.root, \n",
    "            textvariable=self.status_var,\n",
    "            relief=tk.SUNKEN, \n",
    "            anchor=tk.W,\n",
    "            font=(\"Arial\", 10),\n",
    "            bg='#f0f0f0'\n",
    "        )\n",
    "        status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "        \n",
    "        # æ·»åŠ ä¸€äº›æç¤º\n",
    "        self.show_welcome_message()\n",
    "    \n",
    "    def show_welcome_message(self):\n",
    "        welcome_text = \"\"\"âœ¨ æ¬¢è¿ä½¿ç”¨ç”µå½±é›†åˆæ¨èç³»ç»Ÿ âœ¨\n",
    "\n",
    "ä½¿ç”¨æ–¹æ³•ï¼š\n",
    "1. åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥å¤šä¸ªç”µå½±åç§°ï¼ˆç”¨é€—å·ã€åˆ†å·æˆ–æ¢è¡Œåˆ†éš”ï¼‰\n",
    "2. é€‰æ‹©æ¨èæ•°é‡å’Œç­–ç•¥\n",
    "3. ç‚¹å‡»ã€Œå¼€å§‹æ¨èã€æŒ‰é’®\n",
    "\n",
    "æ¨èç­–ç•¥è¯´æ˜ï¼š\n",
    "â€¢ å¹³å‡ç›¸ä¼¼åº¦ï¼šè®¡ç®—ä¸æ‰€æœ‰è¾“å…¥ç”µå½±çš„å¹³å‡ç›¸ä¼¼åº¦\n",
    "â€¢ æœ€å¤§ç›¸ä¼¼åº¦ï¼šå–ä¸ä»»æ„è¾“å…¥ç”µå½±çš„æœ€å¤§ç›¸ä¼¼åº¦  \n",
    "â€¢ å¹¶é›†ç›¸ä¼¼åº¦ï¼šå–ä¸æ‰€æœ‰è¾“å…¥ç”µå½±çš„ç›¸ä¼¼åº¦ä¸­çš„â€œæœ€å°å€¼â€ï¼Œå¼ºè°ƒåŒæ—¶ç›¸ä¼¼\n",
    "\n",
    "ç¤ºä¾‹è¾“å…¥ï¼š\n",
    "è‚–ç”³å…‹çš„æ•‘èµ, éœ¸ç‹åˆ«å§¬, é˜¿ç”˜æ­£ä¼ \n",
    "æˆ–ï¼š\n",
    "è‚–ç”³å…‹çš„æ•‘èµ\n",
    "éœ¸ç‹åˆ«å§¬\n",
    "é˜¿ç”˜æ­£ä¼ \n",
    "\n",
    "æç¤ºï¼šç¡®ä¿è¾“å…¥æ­£ç¡®çš„ç”µå½±åç§°\n",
    "\"\"\"\n",
    "        self.result_text.insert(tk.END, welcome_text)\n",
    "        self.result_text.config(state=tk.DISABLED)\n",
    "    \n",
    "    def clear_input(self):\n",
    "        \"\"\"æ¸…ç©ºè¾“å…¥æ¡†\"\"\"\n",
    "        self.movies_text.delete(1.0, tk.END)\n",
    "        self.status_var.set(\"è¾“å…¥å·²æ¸…ç©º\")\n",
    "    \n",
    "    def parse_movie_input(self, input_text):\n",
    "        \"\"\"è§£æç”¨æˆ·è¾“å…¥çš„ç”µå½±é›†åˆ\"\"\"\n",
    "        # æ›¿æ¢å„ç§åˆ†éš”ç¬¦ä¸ºé€—å·\n",
    "        input_text = input_text.replace(';', ',').replace('ï¼›', ',').replace('ï¼Œ', ',').replace('\\n', ',')\n",
    "        # åˆ†å‰²å¹¶æ¸…ç†\n",
    "        movies = [movie.strip() for movie in input_text.split(',') if movie.strip()]\n",
    "        return movies\n",
    "    \n",
    "    def recommend_movies(self):\n",
    "        \"\"\"åŸºäºç”µå½±é›†åˆè¿›è¡Œæ¨è\"\"\"\n",
    "        input_text = self.movies_text.get(1.0, tk.END).strip()\n",
    "        if not input_text:\n",
    "            messagebox.showwarning(\"è¾“å…¥é”™è¯¯\", \"è¯·è¾“å…¥ç”µå½±åç§°\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            topk = int(self.topk_var.get())\n",
    "            strategy = self.strategy_var.get()\n",
    "        except ValueError:\n",
    "            messagebox.showwarning(\"è¾“å…¥é”™è¯¯\", \"æ¨èæ•°é‡å¿…é¡»æ˜¯æ•°å­—\")\n",
    "            return\n",
    "        \n",
    "        # è§£æè¾“å…¥çš„ç”µå½±é›†åˆ\n",
    "        input_movies = self.parse_movie_input(input_text)\n",
    "        if not input_movies:\n",
    "            messagebox.showwarning(\"è¾“å…¥é”™è¯¯\", \"æœªæ‰¾åˆ°æœ‰æ•ˆçš„ç”µå½±åç§°\")\n",
    "            return\n",
    "        \n",
    "        self.status_var.set(f\"æ­£åœ¨å¤„ç† {len(input_movies)} éƒ¨ç”µå½±...\")\n",
    "        self.root.update()\n",
    "        \n",
    "        # æ¸…ç©ºä¹‹å‰çš„ç»“æœ\n",
    "        self.result_text.config(state=tk.NORMAL)\n",
    "        self.result_text.delete(1.0, tk.END)\n",
    "        \n",
    "        # è°ƒç”¨æ¨èå‡½æ•°\n",
    "        try:\n",
    "            result_df = self.get_collection_recommendations(input_movies, topk, strategy)\n",
    "            \n",
    "            if result_df is None or result_df.empty:\n",
    "                self.result_text.insert(tk.END, f\"âŒ æ¨èå¤±è´¥\\n\\n\")\n",
    "                self.result_text.insert(tk.END, \"ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥ç”µå½±åç§°æ˜¯å¦æ­£ç¡®\")\n",
    "                self.status_var.set(\"æ¨èå¤±è´¥\")\n",
    "            else:\n",
    "                # æ˜¾ç¤ºæ¨èç»“æœ\n",
    "                self.display_collection_recommendations(input_movies, result_df, topk, strategy)\n",
    "                self.status_var.set(f\"æ¨èå®Œæˆ - æ‰¾åˆ° {len(result_df)} éƒ¨æ¨èç”µå½±ï¼ˆ{self.sim_source}ï¼‰\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.result_text.insert(tk.END, f\"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}\")\n",
    "            self.status_var.set(\"å‘ç”Ÿé”™è¯¯\")\n",
    "        \n",
    "        self.result_text.config(state=tk.DISABLED)\n",
    "    \n",
    "    def get_collection_recommendations(self, movie_names, topk=10, strategy='average'):\n",
    "        \"\"\"åŸºäºç”µå½±é›†åˆçš„æ¨èå‡½æ•°\"\"\"\n",
    "        try:\n",
    "            df = self.movies_df\n",
    "            sim = self.similarity\n",
    "\n",
    "            # éªŒè¯è¾“å…¥ç”µå½±\n",
    "            valid_movies = []\n",
    "            invalid_movies = []\n",
    "            input_indices = []\n",
    "            \n",
    "            for movie in movie_names:\n",
    "                movie_matches = df[df['NAME'] == movie]\n",
    "                if len(movie_matches) > 0:\n",
    "                    valid_movies.append(movie)\n",
    "                    movie_idx = movie_matches.index[0]\n",
    "                    pos = list(df.index).index(movie_idx)\n",
    "                    input_indices.append(pos)\n",
    "                else:\n",
    "                    invalid_movies.append(movie)\n",
    "            \n",
    "            if not valid_movies:\n",
    "                return None\n",
    "            \n",
    "            # è®°å½•æ— æ•ˆç”µå½±ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰\n",
    "            self.invalid_movies = invalid_movies\n",
    "            \n",
    "            # æ ¹æ®ç­–ç•¥è®¡ç®—ç»¼åˆç›¸ä¼¼åº¦\n",
    "            rows = [sim[i] for i in input_indices]\n",
    "            if strategy == 'average':\n",
    "                combined_similarity = np.mean(rows, axis=0)\n",
    "            elif strategy == 'maximum':\n",
    "                combined_similarity = np.max(rows, axis=0)\n",
    "            elif strategy == 'union':\n",
    "                # â€œå¹¶é›†ç›¸ä¼¼åº¦â€ï¼šå¼ºè°ƒå¯¹æ‰€æœ‰è¾“å…¥éƒ½ä¸ä½çš„å€™é€‰ â†’ å–æœ€å°å€¼\n",
    "                combined_similarity = np.min(rows, axis=0)\n",
    "            else:\n",
    "                combined_similarity = np.mean(rows, axis=0)\n",
    "            \n",
    "            # æ’åºå’Œè¿‡æ»¤\n",
    "            sim_scores = list(enumerate(combined_similarity))\n",
    "            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "            # æ’é™¤è¾“å…¥ç”µå½±æœ¬èº«\n",
    "            sim_scores = [(i, score) for i, score in sim_scores if i not in input_indices]\n",
    "            \n",
    "            if not sim_scores:\n",
    "                return None\n",
    "            \n",
    "            # å–å‰topkä¸ª\n",
    "            top_indices = [i for i, score in sim_scores[:topk]]\n",
    "            top_scores = [score for i, score in sim_scores[:topk]]\n",
    "            \n",
    "            # æ„å»ºç»“æœ\n",
    "            recs = []\n",
    "            for j, sim_score in zip(top_indices, top_scores):\n",
    "                movie_data = df.iloc[j]\n",
    "                rec = {\n",
    "                    \"ç”µå½±å\": movie_data['NAME'],\n",
    "                    \"è±†ç“£è¯„åˆ†\": movie_data.get('DOUBAN_SCORE', np.nan),\n",
    "                    \"ç»¼åˆç›¸ä¼¼åº¦\": float(sim_score)\n",
    "                }\n",
    "                # å¯é€‰ä¿¡æ¯\n",
    "                if 'DIRECTORS' in df.columns:\n",
    "                    rec[\"å¯¼æ¼”\"] = movie_data.get('DIRECTORS', 'æœªçŸ¥')\n",
    "                if 'YEAR' in df.columns:\n",
    "                    rec[\"å¹´ä»½\"] = movie_data.get('YEAR', 'æœªçŸ¥')\n",
    "                recs.append(rec)\n",
    "            \n",
    "            return pd.DataFrame(recs)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"æ¨èè¿‡ç¨‹ä¸­å‡ºé”™: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def display_collection_recommendations(self, input_movies, result_df, topk, strategy):\n",
    "        \"\"\"æ˜¾ç¤ºç”µå½±é›†åˆçš„æ¨èç»“æœ\"\"\"\n",
    "        # ç­–ç•¥åç§°æ˜ å°„\n",
    "        strategy_names = {\n",
    "            'average': 'å¹³å‡ç›¸ä¼¼åº¦',\n",
    "            'maximum': 'æœ€å¤§ç›¸ä¼¼åº¦', \n",
    "            'union': 'å¹¶é›†ç›¸ä¼¼åº¦'\n",
    "        }\n",
    "        \n",
    "        strategy_name = strategy_names.get(strategy, strategy)\n",
    "        \n",
    "        # æ„å»ºè¾“å‡ºæ–‡æœ¬\n",
    "        output = f\"\"\"\n",
    "ğŸ¬ ç”µå½±é›†åˆæ¨èç»“æœ\n",
    "{'='*60}\n",
    "ğŸ“š è¾“å…¥ç”µå½±: {', '.join(input_movies)}\n",
    "ğŸ¯ æ¨èç­–ç•¥: {strategy_name}\n",
    "ğŸ“Š æ¨èæ•°é‡: {topk} éƒ¨\n",
    "ğŸ”§ ç›¸ä¼¼åº¦æ¥æº: {self.sim_source}\n",
    "{'='*60}\n",
    "\n",
    "\"\"\"\n",
    "        # æ˜¾ç¤ºæ— æ•ˆç”µå½±è­¦å‘Š\n",
    "        if hasattr(self, 'invalid_movies') and self.invalid_movies:\n",
    "            output += f\"âš ï¸  æœªæ‰¾åˆ°ä»¥ä¸‹ç”µå½±: {', '.join(self.invalid_movies)}\\n\\n\"\n",
    "        \n",
    "        # æ˜¾ç¤ºæ¨èç»“æœ\n",
    "        for i, row in result_df.iterrows():\n",
    "            similarity_score = row['ç»¼åˆç›¸ä¼¼åº¦']\n",
    "            \n",
    "            # ä½™å¼¦ç›¸ä¼¼åº¦çš„ç®€å•åˆ†æ¡£ï¼ˆå¯æŒ‰ä½ çš„æ•°æ®åˆ†å¸ƒå¾®è°ƒï¼‰\n",
    "            if similarity_score > 0.7:\n",
    "                sim_symbol = \"ã€é«˜ç›¸ä¼¼ã€‘\"\n",
    "            elif similarity_score > 0.5:\n",
    "                sim_symbol = \"ã€ä¸­ç›¸ä¼¼ã€‘\" \n",
    "            elif similarity_score > 0.3:\n",
    "                sim_symbol = \"ã€ä½ç›¸ä¼¼ã€‘\"\n",
    "            else:\n",
    "                sim_symbol = \"ã€ä¸€èˆ¬ã€‘\"\n",
    "            \n",
    "            output += f\"{i+1:2d}. {sim_symbol} ã€Š{row['ç”µå½±å']}ã€‹\\n\"\n",
    "            output += f\"    â­ è¯„åˆ†: {row['è±†ç“£è¯„åˆ†']} | ğŸ“Š ç»¼åˆç›¸ä¼¼åº¦: {similarity_score:.3f}\\n\"\n",
    "            \n",
    "            if 'å¯¼æ¼”' in row and row['å¯¼æ¼”'] != 'æœªçŸ¥':\n",
    "                output += f\"    ğŸ¥ å¯¼æ¼”: {row['å¯¼æ¼”']}\\n\"\n",
    "            if 'å¹´ä»½' in row and row['å¹´ä»½'] != 'æœªçŸ¥':\n",
    "                output += f\"    ğŸ“… å¹´ä»½: {row['å¹´ä»½']}\\n\"\n",
    "            \n",
    "            if i < len(result_df) - 1:\n",
    "                output += \"    \" + \"â”€\" * 50 + \"\\n\"\n",
    "        \n",
    "        output += f\"\"\"\n",
    "{'='*60}\n",
    "âœ… æ¨èå®Œæˆï¼åŸºäº {len(input_movies)} éƒ¨è¾“å…¥ç”µå½±ï¼Œæ‰¾åˆ° {len(result_df)} éƒ¨æ¨èç”µå½±\n",
    "ğŸ“ˆ å¹³å‡ç›¸ä¼¼åº¦: {result_df['ç»¼åˆç›¸ä¼¼åº¦'].mean():.3f}\n",
    "\"\"\"\n",
    "        \n",
    "        self.result_text.insert(tk.END, output)\n",
    "\n",
    "# å¯åŠ¨åº”ç”¨ç¨‹åº\n",
    "def start_collection_gui():\n",
    "    root = tk.Tk()\n",
    "    app = MovieCollectionRecommendationApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "# è¿è¡ŒGUI\n",
    "if __name__ == \"__main__\":\n",
    "    # ç°åœ¨æ”¯æŒä¸¤ç§ä¸Šæ¸¸è¾“å…¥ï¼š\n",
    "    # 1) movies_new + similarityï¼ˆä»»æ„æ¥æºï¼šBOW/AE/VAE/DVAEï¼‰\n",
    "    # 2) movies_new + featureï¼ˆå¦‚ DVAE çš„ z_meanï¼‰ï¼ŒGUI ä¼šè‡ªåŠ¨ç”¨ä½™å¼¦æ„å»º similarity\n",
    "    if 'movies_new' not in globals():\n",
    "        print(\"é”™è¯¯: è¯·å…ˆå‡†å¤‡ movies_newï¼ˆç”µå½±æ•°æ®è¡¨ï¼‰\")\n",
    "    else:\n",
    "        # è‹¥æ²¡æœ‰ similarity ä½†æœ‰ featureï¼Œä¼šè‡ªåŠ¨æ„å»ºï¼›è‹¥éƒ½æ²¡æœ‰ä¼šæŠ¥é”™æç¤º\n",
    "        start_collection_gui()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
