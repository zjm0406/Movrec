{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e90681ce-274f-45ea-b363-2cc59f966c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "movies=pd.read_csv('movies.csv')\n",
    "movies_db=pd.read_csv('movies_db.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7d32fe-8598-4d77-a276-0c161b824e04",
   "metadata": {},
   "source": [
    "### 1.数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a9e8a82f-7927-4898-bada-648184ed3d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1172 entries, 0 to 1171\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   subject_id  1172 non-null   object\n",
      " 1   title       1172 non-null   object\n",
      " 2   year        1172 non-null   object\n",
      " 3   rating      1168 non-null   object\n",
      " 4   directors   1169 non-null   object\n",
      " 5   INFO        1172 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 55.1+ KB\n"
     ]
    }
   ],
   "source": [
    "movies_db=movies_db.drop(\n",
    "    columns=['durations','votes']\n",
    ")\n",
    "movies_db['INFO'] = (\n",
    "    movies_db['genres'].fillna('').astype(str) + ' ' +\n",
    "    movies_db['countries'].fillna('').astype(str) + ' ' +\n",
    "    movies_db['reviews'].fillna('').astype(str)\n",
    ")\n",
    "\n",
    "movies_db = movies_db.drop(columns=['genres', 'countries', 'reviews'])\n",
    "movies_db['title'] = movies_db['title'].apply(lambda x: ''.join(re.findall(r'[\\u4e00-\\u9fff]+', str(x))))\n",
    "movies_db.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e5479d-a17e-4ca0-8922-d2a80c3439ba",
   "metadata": {},
   "source": [
    "删除无用列并只保留评分大于6.5的电影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c5e5bc38-02d2-4c94-a462-55a568c45ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.drop(\n",
    "    columns=['COVER','IMDB_ID','MINS','OFFICIAL_SITE','RELEASE_DATE','SLUG','ACTOR_IDS','DIRECTOR_IDS','LANGUAGES','GENRES','ALIAS','ACTORS']\n",
    ")\n",
    "movies = movies[movies['DOUBAN_SCORE'] >= 6.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12251fd-378e-479a-9c3c-357c235ec45b",
   "metadata": {},
   "source": [
    "筛选评分人数大于5000的电影并降序排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "100e8223-7846-4eec-930a-e8434df5b53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new = movies[(movies['DOUBAN_VOTES'] >= 3000)].sort_values(by=['DOUBAN_SCORE','DOUBAN_VOTES'], ascending=[False,False])[['DIRECTORS','MOVIE_ID','NAME','DOUBAN_SCORE','STORYLINE','TAGS','REGIONS','YEAR']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f280483-5565-4977-836b-4cd4dce27a0a",
   "metadata": {},
   "source": [
    "### 2.余弦相似度模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eedd4aa0-ef2f-41a2-ba96-c0c59125c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_new['INFO'] = (\n",
    "    movies['STORYLINE'].fillna('').astype(str) + \" \" +\n",
    "    movies['TAGS'].fillna('').astype(str) + \" \" +\n",
    "    movies['REGIONS'].fillna('').astype(str)\n",
    "#    + \" \" +\n",
    "#    movies['DIRECTORS'].fillna('').astype(str) + \" \" +\n",
    "#    movies['ACTORS'].fillna('').astype(str) + \" \" +\n",
    "#    movies['YEAR'].fillna('').astype(str)\n",
    ")\n",
    "movies_new = movies_new.drop(columns=['STORYLINE', 'TAGS', 'REGIONS'\n",
    "                                      #, 'DIRECTORS', 'ACTORS', 'YEAR'\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5fe8b7f6-9dc8-4105-b2ff-d58e59db50e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5058 entries, 0 to 5057\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   DIRECTORS     4913 non-null   object\n",
      " 1   MOVIE_ID      5058 non-null   object\n",
      " 2   NAME          5058 non-null   object\n",
      " 3   DOUBAN_SCORE  5054 non-null   object\n",
      " 4   YEAR          5058 non-null   object\n",
      " 5   INFO          5058 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 237.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "movies_db_renamed = movies_db.rename(columns={\n",
    "    'subject_id': 'MOVIE_ID',\n",
    "    'title': 'NAME',\n",
    "    'year': 'YEAR',\n",
    "    'rating': 'DOUBAN_SCORE',\n",
    "    'directors': 'DIRECTORS'\n",
    "})\n",
    "movies_db_renamed = movies_db_renamed[['DIRECTORS', 'MOVIE_ID', 'NAME', 'DOUBAN_SCORE', 'YEAR', 'INFO']]\n",
    "movies_new = pd.concat([movies_new, movies_db_renamed], ignore_index=True)\n",
    "\n",
    "print(movies_new.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "48f54daa-d56d-4f1f-abcb-c724bfe06ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "director_label = pd.read_csv(\"director_label.csv\")\n",
    "director_to_label = dict(zip(director_label[\"DIRECTOR\"], director_label[\"LABEL\"]))\n",
    "movies_new[\"LABEL\"] = movies_new[\"DIRECTORS\"].apply(\n",
    "    lambda x: \",\".join({director_to_label.get(d.strip()) for d in str(x).split(\"/\") if director_to_label.get(d.strip())})\n",
    "    if pd.notna(x) else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6111ca22-bc8d-40c1-912c-eaebc77d8c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5058 entries, 0 to 5057\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   DIRECTORS     4913 non-null   object\n",
      " 1   MOVIE_ID      5058 non-null   object\n",
      " 2   NAME          5058 non-null   object\n",
      " 3   DOUBAN_SCORE  5054 non-null   object\n",
      " 4   YEAR          5058 non-null   object\n",
      " 5   INFO          5058 non-null   object\n",
      " 6   LABEL         4913 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 276.7+ KB\n"
     ]
    }
   ],
   "source": [
    "movies_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ea069d99-9363-4741-8bd3-32b733adab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "308629b3-bc33-486b-bb5a-64e9dff3ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中文分词器\n",
    "def chinese_tokenizer(text):\n",
    "    return jieba.lcut(str(text))\n",
    "stopwords = [\n",
    "    \"的\", \"了\", \"在\", \"是\", \"我\", \"有\", \"和\", \"就\", \"不\", \"人\", \n",
    "    \"都\", \"一\", \"一个\", \"上\", \"也\", \"很\", \"到\", \"说\", \"要\", \"去\",\n",
    "    \"你\", \"会\", \"着\", \"没有\", \"看\", \"好\", \"自己\", \"这\", \"那\", \n",
    "    \"为\", \"之\", \"对\", \"与\", \"而\", \"并\", \"等\", \"被\", \"及\", \"或\",\n",
    "    \"但\", \"所以\", \"如果\", \"因为\", \"然后\", \"而且\", \"那么\", \"他们\", \n",
    "    \"我们\", \"你们\", \"它们\", \"什么\", \"哪个\", \"哪些\", \"哪里\", \"时候\",\n",
    "    \"他\", \"她\", \"它\", \"咱们\", \"大家\", \"谁\", \"怎样\", \"怎么\", \"多少\", \"为什么\",\n",
    "    \"这里\", \"那里\", \"这样\", \"那样\", \"这个\", \"那个\", \"这些\", \"那些\",\n",
    "    \"地\", \"得\", \"所\", \"过\", \"吗\", \"呢\", \"吧\", \"啊\", \"呀\", \"嘛\", \"哇\", \"啦\",\n",
    "    \"从\", \"自\", \"以\", \"向\", \"关于\", \"对于\", \"根据\", \"按照\", \"通过\", \"由于\",\n",
    "    \"并且\", \"或者\", \"虽然\", \"即使\", \"尽管\", \"不管\", \"只要\", \"只有\", \"除非\",\n",
    "    \"最\", \"太\", \"更\", \"非常\", \"十分\", \"特别\", \"极其\", \"比较\", \"稍微\", \"有点\",\n",
    "    \"刚\", \"才\", \"正在\", \"已经\", \"曾经\", \"马上\", \"立刻\", \"永远\", \"一直\", \"总是\",\n",
    "    \"常常\", \"经常\", \"往往\", \"不断\", \"偶尔\", \"又\", \"再\", \"还\", \"仅\", \"光\",\n",
    "    \"能\", \"能够\", \"可以\", \"可能\", \"应该\", \"应当\", \"想\", \"愿意\", \"肯\", \"敢\",\n",
    "    \"来\", \"去\", \"进\", \"出\", \"回\", \"起\", \"开\",\n",
    "    \"些\", \"一些\", \"所有\", \"每个\", \"某个\", \"各种\", \"多个\", \"几个\", \"第一\", \"第二\",\n",
    "    \"就是\", \"只是\", \"可是\", \"真是\", \"也是\", \"不是\", \"也是\", \"就是\", \"正是\",\n",
    "    \"一样\", \"一般\", \"一点\", \"一起\", \"一直\", \"一下\", \"一些\", \"一种\", \"一次\"\n",
    "]\n",
    "cv = CountVectorizer(\n",
    "    max_features=10000,\n",
    "    tokenizer=chinese_tokenizer,\n",
    "    stop_words=stopwords, \n",
    "    token_pattern=None  \n",
    ")\n",
    "\n",
    "vector = cv.fit_transform(movies_new['INFO'].astype(str)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "57a6fe53-971b-4ded-b2ce-f0b2663f3b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 132ms/step - loss: 0.0486 - val_loss: 0.0869\n",
      "Epoch 2/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - loss: 0.0198 - val_loss: 0.0610\n",
      "Epoch 3/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - loss: 0.0148 - val_loss: 0.0466\n",
      "Epoch 4/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - loss: 0.0130 - val_loss: 0.0408\n",
      "Epoch 5/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 211ms/step - loss: 0.0123 - val_loss: 0.0371\n",
      "Epoch 6/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - loss: 0.0117 - val_loss: 0.0345\n",
      "Epoch 7/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 276ms/step - loss: 0.0113 - val_loss: 0.0335\n",
      "Epoch 8/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - loss: 0.0110 - val_loss: 0.0333\n",
      "Epoch 9/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - loss: 0.0107 - val_loss: 0.0318\n",
      "Epoch 10/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - loss: 0.0104 - val_loss: 0.0307\n",
      "Epoch 11/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - loss: 0.0102 - val_loss: 0.0295\n",
      "Epoch 12/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - loss: 0.0100 - val_loss: 0.0294\n",
      "Epoch 13/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - loss: 0.0098 - val_loss: 0.0289\n",
      "Epoch 14/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - loss: 0.0096 - val_loss: 0.0285\n",
      "Epoch 15/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - loss: 0.0096 - val_loss: 0.0278\n",
      "Epoch 16/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 153ms/step - loss: 0.0094 - val_loss: 0.0277\n",
      "Epoch 17/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - loss: 0.0094 - val_loss: 0.0271\n",
      "Epoch 18/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - loss: 0.0093 - val_loss: 0.0272\n",
      "Epoch 19/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - loss: 0.0092 - val_loss: 0.0267\n",
      "Epoch 20/20\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - loss: 0.0091 - val_loss: 0.0266\n"
     ]
    }
   ],
   "source": [
    "# ========= 去噪变分自编码器（DVAE）— 稳定版（自定义Layer加KL） =========\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "inp_dim    = vector.shape[1]\n",
    "code_dim   = 64            # 可改 64/128\n",
    "epochs     = 20\n",
    "batch_size = 256\n",
    "beta_kl    = 1.0          # β-VAE 系数\n",
    "\n",
    "# 确保 dtype 稳定\n",
    "vector = vector.astype(\"float32\", copy=False)\n",
    "\n",
    "# --- 编码器：输入端去噪 ---\n",
    "inputs = keras.Input(shape=(inp_dim,), name=\"bow_counts\")\n",
    "x = keras.layers.GaussianNoise(0.15)(inputs)          # 去噪；也可换 Dropout(0.3)\n",
    "x = keras.layers.Dense(1000, activation=\"selu\")(x)\n",
    "x = keras.layers.Dense(256,  activation=\"selu\")(x)\n",
    "z_mean   = keras.layers.Dense(code_dim, name=\"z_mean\")(x)\n",
    "z_logvar = keras.layers.Dense(code_dim, name=\"z_logvar\")(x)\n",
    "\n",
    "def reparameterize(args):\n",
    "    mu, logvar = args\n",
    "    eps = tf.random.normal(shape=tf.shape(mu))\n",
    "    return mu + tf.exp(0.5 * logvar) * eps\n",
    "\n",
    "z = keras.layers.Lambda(reparameterize, name=\"z\")([z_mean, z_logvar])\n",
    "\n",
    "# 打包一个 encoder（包含三个输出：mean, logvar, z）\n",
    "encoder = keras.Model(inputs, [z_mean, z_logvar, z], name=\"dvae_encoder\")\n",
    "\n",
    "# --- 解码器：线性输出，用 MSE 重构计数 ---\n",
    "latent_inputs = keras.Input(shape=(code_dim,), name=\"z_in\")\n",
    "d = keras.layers.Dense(256,  activation=\"selu\")(latent_inputs)\n",
    "d = keras.layers.Dense(1000, activation=\"selu\")(d)\n",
    "recons = keras.layers.Dense(inp_dim, activation=None, name=\"recon\")(d)\n",
    "decoder = keras.Model(latent_inputs, recons, name=\"dvae_decoder\")\n",
    "\n",
    "# --- 自定义 KL 层：把 KL 正则通过 layer.add_loss() 注入 ---\n",
    "class KLDivergenceLayer(keras.layers.Layer):\n",
    "    def __init__(self, beta=1.0, scale=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.beta = beta\n",
    "        self.scale = scale  # 用于与 MSE 标度对齐\n",
    "\n",
    "    def call(self, inputs):\n",
    "        mu, logvar = inputs\n",
    "        # KL = -0.5 * sum(1 + logvar - exp(logvar) - mu^2)\n",
    "        kl_per_sample = -0.5 * tf.reduce_sum(\n",
    "            1.0 + logvar - tf.exp(logvar) - tf.square(mu), axis=1\n",
    "        )\n",
    "        kl = tf.reduce_mean(kl_per_sample) / float(self.scale)\n",
    "        self.add_loss(self.beta * kl)\n",
    "        # 返回个“占位输出”，不参与后续计算\n",
    "        return tf.zeros_like(mu[:, :1])\n",
    "\n",
    "# --- 组装 DVAE：重构 + KL层（只为加loss，不改计算图）---\n",
    "z_mean_out, z_logvar_out, z_out = encoder(inputs)\n",
    "_ = KLDivergenceLayer(beta=beta_kl, scale=inp_dim, name=\"kl_reg\")([z_mean_out, z_logvar_out])\n",
    "recons_out = decoder(z_out)\n",
    "\n",
    "vae = keras.Model(inputs, recons_out, name=\"dvae\")\n",
    "\n",
    "# --- 训练：重构用 MSE；KL 已由 KL 层注入 ---\n",
    "vae.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mse\")\n",
    "vae.fit(vector, vector, epochs=epochs, batch_size=batch_size, validation_split=0.1, verbose=1)\n",
    "\n",
    "# --- 用 z_mean 作为电影向量（更稳、更可插值）---\n",
    "z_mean_val = encoder.predict(vector, verbose=0)[0]   # 形状: [N, code_dim]\n",
    "feature = z_mean_val\n",
    "\n",
    "# ========= DVAE 结束 =========\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3d96bd8f-46b9-4c89-8143-6cd5ac72dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "52e7374e-5af3-4825-8f95-e94e501adba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommand(movie_name, sample_top=15, pick_n=5):\n",
    "    label_idx = movies_new.index[movies_new['NAME'] == movie_name]\n",
    "    if len(label_idx) == 0:\n",
    "        print(\"未找到该影片\")\n",
    "        return\n",
    "    pos = movies_new.index.get_loc(label_idx[0])\n",
    "\n",
    "    sims = similarity[pos]\n",
    "    cand = np.argsort(-sims)   # 按相似度降序排列索引\n",
    "    cand = cand[cand != pos]   # 去掉自身\n",
    "    top_candidates = cand[:sample_top]  # 取前15个\n",
    "    \n",
    "    # 如果数量足够，从前15中随机选5个（无放回）\n",
    "    n_pick = min(pick_n, len(top_candidates))\n",
    "    selected = np.random.choice(top_candidates, n_pick, replace=False)\n",
    "\n",
    "    recs = []\n",
    "    for j in selected:\n",
    "        recs.append({\n",
    "            \"电影名\": movies_new.iloc[j]['NAME'],\n",
    "            \"豆瓣评分\": movies_new.iloc[j]['DOUBAN_SCORE'],\n",
    "            \"流派\": movies_new.iloc[j]['LABEL'],\n",
    "            \"相似度\": sims[j],\n",
    "            \"导演\": movies_new.iloc[j]['DIRECTORS']\n",
    "        })\n",
    "    df = pd.DataFrame(recs).sort_values(by=\"相似度\", ascending=False).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ecd2bed3-7fef-4693-92a0-323f1ff44da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "USER_LIKE = \"user_wish.csv\"\n",
    "USER_DISLIKE = \"user_dislike.csv\"\n",
    "REQUIRED = [\"douban_id\", \"title\", \"info\", \"mark_time\", \"my_rating_stars\", \"my_rating_label\"]\n",
    "\n",
    "SCHEMA = {\n",
    "    \"douban_id\": \"Int64\",     # 可空整型\n",
    "    \"title\": \"string\",\n",
    "    \"info\": \"string\",\n",
    "    \"mark_time\": \"string\",\n",
    "    \"my_rating_stars\": \"Float64\",  # 可空浮点\n",
    "    \"my_rating_label\": \"string\",\n",
    "}\n",
    "\n",
    "def _empty_df_with_schema():\n",
    "    return pd.DataFrame({c: pd.Series(dtype=t) for c, t in SCHEMA.items()})[REQUIRED]\n",
    "\n",
    "def _ensure_csv(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        _empty_df_with_schema().to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "def _read_csv(path: str) -> pd.DataFrame:\n",
    "    _ensure_csv(path)\n",
    "    df = pd.read_csv(path, encoding=\"utf-8-sig\")\n",
    "    # 补齐缺列并按 schema 强制类型\n",
    "    for c in REQUIRED:\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "    df = df[REQUIRED].copy()\n",
    "    for c, t in SCHEMA.items():\n",
    "        try:\n",
    "            if t == \"Int64\":\n",
    "                df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Int64\")\n",
    "            elif t == \"Float64\":\n",
    "                df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Float64\")\n",
    "            else:\n",
    "                df[c] = df[c].astype(\"string\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    return df\n",
    "\n",
    "def _record_from_movies_new_by_title(title: str) -> pd.DataFrame | None:\n",
    "    \"\"\"从 movies_new 里用片名精确匹配一行，并转为六列记录；找不到返回 None\"\"\"\n",
    "    m = movies_new.loc[movies_new[\"NAME\"] == title]\n",
    "    if m.empty:\n",
    "        return None\n",
    "    r = m.iloc[0]\n",
    "    rec = {\n",
    "        \"douban_id\": r.get(\"MOVIE_ID\", pd.NA),\n",
    "        \"title\": r.get(\"NAME\", pd.NA),\n",
    "        \"info\": r.get(\"INFO\", pd.NA),\n",
    "        \"mark_time\": pd.NA,            # 初始无标记时间\n",
    "        \"my_rating_stars\": pd.NA,      # 初始无个人评分\n",
    "        \"my_rating_label\": pd.NA,      # 初始无标签\n",
    "    }\n",
    "    return pd.DataFrame([rec], columns=REQUIRED)\n",
    "\n",
    "def _write_union(path: str, rec_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"把一条规范记录写入 path，并按 douban_id 去重；返回写入后的 DataFrame\"\"\"\n",
    "    # 先把新纪录也套用 schema\n",
    "    rec_df = rec_df.reindex(columns=REQUIRED)\n",
    "    for c, t in SCHEMA.items():\n",
    "        try:\n",
    "            if t == \"Int64\":\n",
    "                rec_df[c] = pd.to_numeric(rec_df[c], errors=\"coerce\").astype(\"Int64\")\n",
    "            elif t == \"Float64\":\n",
    "                rec_df[c] = pd.to_numeric(rec_df[c], errors=\"coerce\").astype(\"Float64\")\n",
    "            else:\n",
    "                rec_df[c] = rec_df[c].astype(\"string\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    df = _read_csv(path)\n",
    "\n",
    "    if df.empty:\n",
    "        out = rec_df.dropna(subset=[\"douban_id\"])\n",
    "    else:\n",
    "        out = pd.concat([rec_df, df], ignore_index=True)\n",
    "        out = out.dropna(subset=[\"douban_id\"]).drop_duplicates(subset=[\"douban_id\"], keep=\"first\")\n",
    "\n",
    "    out = out[REQUIRED]\n",
    "    out.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    return out  # ← 返回最新表\n",
    "\n",
    "def _remove_by_id(path: str, douban_id_val) -> pd.DataFrame:\n",
    "    \"\"\"从 path 中移除某 douban_id；返回删除后的 DataFrame\"\"\"\n",
    "    df = _read_csv(path)\n",
    "    df[\"douban_id\"] = pd.to_numeric(df[\"douban_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df = df[df[\"douban_id\"] != pd.Series([douban_id_val]).astype(\"Int64\").iloc[0]]\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    return df  # ← 返回最新表\n",
    "\n",
    "def _feedback(title: str, like: bool = True) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"把片名对应的 movies_new 行格式化后写入 like/dislike，并保持互斥；\n",
    "       返回 (wish_new_df, dislike_new_df)\"\"\"\n",
    "    rec = _record_from_movies_new_by_title(title)\n",
    "    if rec is None:\n",
    "        print(f\"未在 movies_new 中找到：{title}\")\n",
    "        return _read_csv(USER_LIKE), _read_csv(USER_DISLIKE)\n",
    "\n",
    "    did = pd.to_numeric(rec.iloc[0][\"douban_id\"], errors=\"coerce\")\n",
    "    if pd.isna(did):\n",
    "        print(f\"该影片缺少 MOVIE_ID，已跳过：{title}\")\n",
    "        return _read_csv(USER_LIKE), _read_csv(USER_DISLIKE)\n",
    "\n",
    "    if like:\n",
    "        wish_new = _write_union(USER_LIKE, rec)\n",
    "        dislike_new = _remove_by_id(USER_DISLIKE, did)\n",
    "        print(f\"✅ 已加入想看：{title}\")\n",
    "    else:\n",
    "        dislike_new = _write_union(USER_DISLIKE, rec)\n",
    "        wish_new = _remove_by_id(USER_LIKE, did)\n",
    "        print(f\"✅ 已加入不喜欢：{title}\")\n",
    "\n",
    "    return wish_new, dislike_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede5d56-19c9-43c9-ad5e-4fe8d92be99c",
   "metadata": {},
   "source": [
    "#### 3.添加个人信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2d1a0c22-b1c2-4f17-b6ab-8d8ee94ed40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_like = \"user_wish.csv\"\n",
    "user_dislike = \"user_dislike.csv\"\n",
    "\n",
    "wish_src = \"me_movies_wish.csv\"\n",
    "done_src = \"me_movies_done.csv\"\n",
    "\n",
    "REQUIRED = [\"douban_id\",\"title\",\"info\",\"mark_time\",\"my_rating_stars\",\"my_rating_label\"]\n",
    "\n",
    "wish = pd.read_csv(wish_src, encoding=\"utf-8-sig\")\n",
    "done = pd.read_csv(done_src, encoding=\"utf-8-sig\")\n",
    "\n",
    "wish = wish.reindex(columns=REQUIRED, fill_value=pd.NA)\n",
    "done = done.reindex(columns=REQUIRED, fill_value=pd.NA)\n",
    "\n",
    "done[\"my_rating_stars\"] = pd.to_numeric(done[\"my_rating_stars\"], errors=\"coerce\")\n",
    "\n",
    "likes_from_done = done[done[\"my_rating_stars\"] >= 4]\n",
    "dislikes_from_done = done[done[\"my_rating_stars\"] <= 2]\n",
    "\n",
    "user_like_df = pd.concat([likes_from_done, wish], ignore_index=True) \\\n",
    "                 .drop_duplicates(subset=[\"douban_id\"], keep=\"first\")\n",
    "\n",
    "user_dislike_df = dislikes_from_done.drop_duplicates(subset=[\"douban_id\"], keep=\"first\")\n",
    "\n",
    "user_like_df.to_csv(user_like, index=False, encoding=\"utf-8-sig\", columns=REQUIRED)\n",
    "user_dislike_df.to_csv(user_dislike, index=False, encoding=\"utf-8-sig\", columns=REQUIRED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ccf06-e3db-4efd-940b-f32dfc3969bc",
   "metadata": {},
   "source": [
    "进行推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ac37e0b4-2352-45f0-9568-ac3cb3844fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "为你推荐：\n",
      "- 躲藏（豆瓣：6.8）\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "喜欢输入 y，不喜欢输入 n（回车跳过，q 结束）： n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已加入不喜欢：躲藏\n",
      "- 屏住呼吸（豆瓣：7.1）\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "喜欢输入 y，不喜欢输入 n（回车跳过，q 结束）： n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已加入不喜欢：屏住呼吸\n",
      "- 超人：钢铁之躯（豆瓣：7.0）\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "喜欢输入 y，不喜欢输入 n（回车跳过，q 结束）： n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已加入不喜欢：超人：钢铁之躯\n",
      "- 不道德的审判（豆瓣：8.2）\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "喜欢输入 y，不喜欢输入 n（回车跳过，q 结束）： y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已加入想看：不道德的审判\n",
      "- 乡愁（豆瓣：9.0）\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "喜欢输入 y，不喜欢输入 n（回车跳过，q 结束）： y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已加入想看：乡愁\n",
      "like条数： 520  | dislike条数： 35\n"
     ]
    }
   ],
   "source": [
    "df = recommand(\"潜行者\", sample_top=15, pick_n=5)\n",
    "if df is None or len(df) == 0:\n",
    "    print(\"没有可推荐的结果。\")\n",
    "else:\n",
    "    print(\"\\n为你推荐：\")\n",
    "    for _, row in df.iterrows():\n",
    "        title = str(row.get(\"电影名\", row.get(\"NAME\", row.get(\"title\", \"\"))))\n",
    "        score = row.get(\"豆瓣评分\", row.get(\"DOUBAN_SCORE\", row.get(\"my_rating_stars\", \"\"))) or \"\"\n",
    "        print(f\"- {title}（豆瓣：{score}）\")\n",
    "\n",
    "        ans = input(\"喜欢输入 y，不喜欢输入 n（回车跳过，q 结束）：\").strip().lower()\n",
    "        if ans == \"y\":\n",
    "            user_like_df, user_dislike_df = _feedback(title, like=True)   # ← 内存立即更新\n",
    "        elif ans == \"n\":\n",
    "            user_like_df, user_dislike_df = _feedback(title, like=False)  # ← 内存立即更新\n",
    "        elif ans == \"q\":\n",
    "            break\n",
    "\n",
    "    print(\"like条数：\", len(user_like_df), \" | dislike条数：\", len(user_dislike_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "eb007a27-fa61-45a1-8ec4-7fa322978192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 520 entries, 0 to 519\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   douban_id        520 non-null    Int64  \n",
      " 1   title            520 non-null    string \n",
      " 2   info             520 non-null    string \n",
      " 3   mark_time        517 non-null    string \n",
      " 4   my_rating_stars  388 non-null    Float64\n",
      " 5   my_rating_label  0 non-null      string \n",
      "dtypes: Float64(1), Int64(1), string(4)\n",
      "memory usage: 25.5 KB\n"
     ]
    }
   ],
   "source": [
    "user_like_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e7b55d-5fda-4e21-82a5-92de21a0034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据id匹配导演和流派"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
